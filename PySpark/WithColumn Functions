
from pyspark.sql import SparkSession


#Invoking SparkSession
spark = SparkSession.builder.appName('test_data').getOrCreate()

#Reading a local File :
df = spark.read.options(header='True',inferschema='True').csv('F:\Arif\Dataset\student-dataset.csv')

#Func : Filter
df.filter(df.city=='Oakland')

#Function : lit
#lit - is used as adding a new column to add static values to all data, Values can either be string type or integer type.

from pyspark.sql.functions import lit

df_city = df.withColumn('new_city',lit('Trichy')).show()
df_city = df.withColumn('new_count',lit('123')).show()

# Function : col
#After withColumn( if you give a new name it will create a new column name, if we give old name it will replace the existing table /data :

from pyspark.sql.functions import col

df_grade = df.withColumn('age',col('age')*10)

df_grade.show()
